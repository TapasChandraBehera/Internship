{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d339e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9386ef",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5458c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries \n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32476e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09cc4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7170cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Data Analyst\" job role as a key value\n",
    "searchJob=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "searchJob.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1daf5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Bangalore\" location as a key value\n",
    "searchLocation=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "searchLocation.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d83d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "searchButton=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "searchButton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0604646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decalring empty sets\n",
    "job_Title=[]\n",
    "job_Location=[]\n",
    "company_Name=[]\n",
    "experience_Required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "878bbb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#Scraping all job title by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job titles inside their relevant empty set\n",
    "titleTags=driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]/a')\n",
    "for i in titleTags[0:11]:\n",
    "    title=i.text\n",
    "    job_Title.append(title)\n",
    "print(len(job_Title))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d87e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all job location by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job locations inside their relevant empty set\n",
    "locationTags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in locationTags[0:11]:\n",
    "    location=i.text\n",
    "    job_Location.append(location)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3605e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all company name by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the company names inside their relevant empty set\n",
    "companyTags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in companyTags[0:11]:\n",
    "    company=i.text\n",
    "    company_Name.append(company)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2736c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all experience by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the experience inside their relevant empty set\n",
    "expTags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in expTags[0:11]:\n",
    "    exp=i.text\n",
    "    experience_Required.append(exp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8718fc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>diraa hr services hiring for mncs</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Modeler data</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Modeller</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst Hiring Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst Hiring Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Name        Location  \\\n",
       "0                                 Data Analyst   Bangalore\\n+3   \n",
       "1                     Vacancy For Data Analyst  Bangalore\\n+14   \n",
       "2                        Clinical Data Analyst   Bangalore\\n+6   \n",
       "3                            Data Modeler data       Bangalore   \n",
       "4                                Data Modeller       Bangalore   \n",
       "5                       Data Modeler Bangalore       Bangalore   \n",
       "6                                 Data Modeler       Bangalore   \n",
       "7                                 Data Analyst   Bangalore\\n+9   \n",
       "8                        Clinical Data Analyst   Bangalore\\n+4   \n",
       "9   Data Analyst Hiring Fresher and Experience  Bangalore\\n+13   \n",
       "10  Data Analyst Hiring Fresher and Experience  Bangalore\\n+13   \n",
       "\n",
       "                              Company Name  Experience  \n",
       "0        diraa hr services hiring for mncs   0 to 1 Yr  \n",
       "1                 yogita staffing solution  0 to 3 Yrs  \n",
       "2                            techno endura   0 to 1 Yr  \n",
       "3   boyen haddin consulting and technol...  3 to 6 Yrs  \n",
       "4   boyen haddin consulting and technol...  3 to 6 Yrs  \n",
       "5   boyen haddin consulting and technol...  3 to 6 Yrs  \n",
       "6   boyen haddin consulting and technol...  3 to 6 Yrs  \n",
       "7                  v-tech data outsourcing  0 to 2 Yrs  \n",
       "8                          quiscon biotech  0 to 2 Yrs  \n",
       "9                        kavya interprises  0 to 4 Yrs  \n",
       "10                       kavya interprises  0 to 4 Yrs  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making data frame by using the datas which are stored inside the empty lists.\n",
    "df=pd.DataFrame({'Job Name':job_Title,'Location':job_Location,'Company Name':company_Name,'Experience':experience_Required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95ca31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "174b0af3",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bfb55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd2\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcf37f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver2=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e5ca2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver2.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3d8aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Data Scientist\" job role as a key value\n",
    "searchjob=driver2.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "searchjob.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a30e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Bangalore\" job location as a key value\n",
    "searchlocation=driver2.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "searchlocation.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f30cdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "searchbutton=driver2.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "searchbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88f0a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decalring empty lists\n",
    "Job_title=[]\n",
    "Job_location=[]\n",
    "Company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d5083f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping all job title by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job titles inside their relevant empty set\n",
    "titlEtags=driver2.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]/a')\n",
    "for i in titlEtags[0:11]:\n",
    "    titlE=i.text\n",
    "    Job_title.append(titlE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b34c24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all job locations by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job locations inside their relevant empty set\n",
    "locatioNtags=driver2.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in locatioNtags[0:11]:\n",
    "    locatioN=i.text\n",
    "    Job_location.append(locatioN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9a70cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all company names by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the company names inside their relevant empty set\n",
    "companYtags=driver2.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in companYtags[0:11]:\n",
    "    companY=i.text\n",
    "    Company_name.append(companY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a4a59ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist/ Principal Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>fractal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>neostats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>aereo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>people staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+2</td>\n",
       "      <td>diraa hr services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pharma Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+13</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job Name    Job Location  \\\n",
       "0                                      Data Scientist   Bangalore\\n+4   \n",
       "1                                      Data Scientist       Bangalore   \n",
       "2       Lead Data Scientist/ Principal Data Scientist   Bangalore\\n+1   \n",
       "3   Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14   \n",
       "4                               Senior Data Scientist   Bangalore\\n+1   \n",
       "5                                 Lead Data Scientist   Bangalore\\n+1   \n",
       "6                                      Data Scientist   Bangalore\\n+7   \n",
       "7                       Data Scientist Urgent Vacancy  Bangalore\\n+14   \n",
       "8                                      Data Scientist   Bangalore\\n+2   \n",
       "9                               Pharma Data Scientist   Bangalore\\n+4   \n",
       "10                          Hiring For Data Scientist  Bangalore\\n+13   \n",
       "\n",
       "                     Company Name  \n",
       "0   acme services private limited  \n",
       "1             ltimindtree limited  \n",
       "2                         fractal  \n",
       "3        yogita staffing solution  \n",
       "4                        neostats  \n",
       "5                           aereo  \n",
       "6       people staffing solutions  \n",
       "7        yogita staffing solution  \n",
       "8               diraa hr services  \n",
       "9                 quiscon biotech  \n",
       "10       yogita staffing solution  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making data frame by using the datas which are stored inside the empty lists.\n",
    "df2=pd2.DataFrame({'Job Name':Job_title,'Job Location':Job_location,'Company Name':Company_name})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673aa19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3ae01b",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "061eef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd3\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8f94d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver3=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "74ac1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver3.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6f6d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Data Scientist\" job role as a key value\n",
    "searchDesignation=driver3.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "searchDesignation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a3926909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "SearchButton=driver3.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "SearchButton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5159b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Delhi\" job location as a key value\n",
    "SearchLocation=driver3.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[1]/input')\n",
    "SearchLocation.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96ef5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "SearchLocation=driver3.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[2]/span/label')\n",
    "SearchLocation.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3603e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "SearchSalary=driver3.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label')\n",
    "SearchSalary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de722992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "ShowResult=driver3.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[4]/button[2]')\n",
    "ShowResult.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "30824c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring empty sets, where datas are stored\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Exp_Required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4e6c67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all job titles by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job titles inside their relevant empty set\n",
    "tItletags=driver3.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]/a')\n",
    "for i in tItletags[0:11]:\n",
    "    tItle=i.text\n",
    "    Job_Title.append(tItle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e36c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all job locations by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the job locations inside their relevant empty set\n",
    "lOcationtags=driver3.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in lOcationtags[0:11]:\n",
    "    lOcation=i.text\n",
    "    Job_Location.append(lOcation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4bf4c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all company names by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the company names inside their relevant empty set\n",
    "cOmpanytags=driver3.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in cOmpanytags[0:11]:\n",
    "    cOmpany=i.text\n",
    "    Company_Name.append(cOmpany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f80c543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all experience by using find_elements method by using relative XPATH & also use \n",
    "#append method inside for loop to store all the experience inside their relevant empty set\n",
    "eXptags=driver3.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in eXptags[0:11]:\n",
    "    eXp=i.text\n",
    "    Exp_Required.append(eXp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0b195160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bioanalytical Research Associates</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Analyst Fresher</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Delhi\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Delhi\\n+9</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biostatistician</td>\n",
       "      <td>Delhi\\n+17</td>\n",
       "      <td>national seeds corporation limited</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clinical Document Specialist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Document Specialist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Name    Location  \\\n",
       "0                      Data Scientist   Delhi\\n+4   \n",
       "1               Clinical Data Analyst   Delhi\\n+6   \n",
       "2   Bioanalytical Research Associates   Delhi\\n+6   \n",
       "3            Clinical Analyst Fresher   Delhi\\n+6   \n",
       "4            Clinical Data Management   Delhi\\n+6   \n",
       "5                        Data Modeler   Delhi\\n+9   \n",
       "6                       Data Engineer   Delhi\\n+9   \n",
       "7                     Biostatistician  Delhi\\n+17   \n",
       "8     Junior Clinical Data Management   Delhi\\n+6   \n",
       "9        Clinical Document Specialist   Delhi\\n+6   \n",
       "10                Document Specialist   Delhi\\n+6   \n",
       "\n",
       "                          Company Name    Experience  \n",
       "0        acme services private limited    3 to 5 Yrs  \n",
       "1                        techno endura     0 to 1 Yr  \n",
       "2                        techno endura     0 to 1 Yr  \n",
       "3                        techno endura     0 to 1 Yr  \n",
       "4                        techno endura     0 to 1 Yr  \n",
       "5              v-tech data outsourcing    0 to 2 Yrs  \n",
       "6               future solution centre  10 to 20 Yrs  \n",
       "7   national seeds corporation limited    2 to 7 Yrs  \n",
       "8                        techno endura     0 to 1 Yr  \n",
       "9                        techno endura     0 to 1 Yr  \n",
       "10                       techno endura     0 to 1 Yr  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making data frame by using the datas which are stored inside the empty lists.\n",
    "df3=pd3.DataFrame({'Job Name':Job_Title,'Location':Job_Location,'Company Name':Company_Name,'Experience':Exp_Required})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b77ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb703dc",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. ProductDescription\n",
    "8. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4db0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd4\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e775aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver4=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25b9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver4.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82e77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Sunglasses\" item as a key value\n",
    "search_item=driver4.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search_item.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95d9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "search_icon=driver4.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "315bbe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n",
      "scraping page 2\n",
      "scraping page 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the brand name from 3 pages by using find_element and find_elements method \n",
    "#along with the absolute & relative XPATH.Then storing all the scraped data to that empty list.\n",
    "brand=[]\n",
    "for i in range(3):\n",
    "    print('scraping page', i+1)\n",
    "    b_name=driver4.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for b in b_name:\n",
    "        brand.append(b.text)\n",
    "    next_button=driver4.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f760057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n",
      "scraping page 2\n",
      "scraping page 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the item description from 3 pages by using find_element and find_elements method \n",
    "#along with the absolute & relative XPATH.Then storing all the scraped data to that empty list.\n",
    "description=[]\n",
    "for j in range(3):\n",
    "    print('scraping page', j+1)\n",
    "    des=driver4.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]/a[1]')\n",
    "    for d in des:\n",
    "        description.append(d.text)\n",
    "    next_button2=driver4.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button2.click()\n",
    "    time.sleep(3)\n",
    "len(description)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f15de687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n",
      "scraping page 2\n",
      "scraping page 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the item prices from 3 pages by using find_element and find_elements method \n",
    "#along with the absolute & relative XPATH.Then storing all the scraped data to that empty list.\n",
    "price=[]\n",
    "for k in range(3):\n",
    "    print('scraping page',k+1)\n",
    "    paisa=driver4.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for p in paisa:\n",
    "        price.append(p.text)\n",
    "    next_button3=driver4.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button3.click()\n",
    "    time.sleep(3)\n",
    "len(price)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8fc46aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Polarized, UV Protection Rectangular, Wayfarer...</td>\n",
       "      <td>₹725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Aviator Sunglasses (60)</td>\n",
       "      <td>₹745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>Polarized, UV Protection Clubmaster Sunglasses...</td>\n",
       "      <td>₹1,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARICKS</td>\n",
       "      <td>Gradient, Night Vision, Polarized, Photochroma...</td>\n",
       "      <td>₹289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Toughened Glass Lens, UV Protection Aviator, W...</td>\n",
       "      <td>₹725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>Polarized Retro Square Sunglasses (52)</td>\n",
       "      <td>₹1,309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Toughened Glass Lens, UV Protection Rectangula...</td>\n",
       "      <td>₹795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (69)</td>\n",
       "      <td>₹315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>Polarized, UV Protection Cat-eye Sunglasses (F...</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>METRONAUT</td>\n",
       "      <td>UV Protection Sunglass</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand Name                                        Description   Price\n",
       "0        AISLIN  Polarized, UV Protection Rectangular, Wayfarer...    ₹725\n",
       "1        AISLIN              UV Protection Aviator Sunglasses (60)    ₹745\n",
       "2   john jacobs  Polarized, UV Protection Clubmaster Sunglasses...  ₹1,989\n",
       "3        ARICKS  Gradient, Night Vision, Polarized, Photochroma...    ₹289\n",
       "4        AISLIN  Toughened Glass Lens, UV Protection Aviator, W...    ₹725\n",
       "..          ...                                                ...     ...\n",
       "95         IDEE             Polarized Retro Square Sunglasses (52)  ₹1,309\n",
       "96       AISLIN  Toughened Glass Lens, UV Protection Rectangula...    ₹795\n",
       "97        NuVew               UV Protection Sports Sunglasses (69)    ₹315\n",
       "98  john jacobs  Polarized, UV Protection Cat-eye Sunglasses (F...  ₹1,999\n",
       "99    METRONAUT                             UV Protection Sunglass    ₹259\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making data frame by using the datas which are stored inside the empty lists.\n",
    "df4=pd4.DataFrame({'Brand Name':brand[:100],'Description':description[:100],'Price':price[:100]})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "990d4a82",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYIJLDFV&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=a38892bb-54fc-4e27-af4c-88d8917c4f8a.MOBFWQ6BXGJCEYNY.SEARCH&ppt=hp&ppn=homepage&ssid=pj0qgnhv8w0000001706160032923&qH=f6cdfdaa9f3c23f3\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "804d9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd5\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e0462ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver5=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83f61a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver5.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYIJLDFV&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=a38892bb-54fc-4e27-af4c-88d8917c4f8a.MOBFWQ6BXGJCEYNY.SEARCH&ppt=hp&ppn=homepage&ssid=pj0qgnhv8w0000001706160032923&qH=f6cdfdaa9f3c23f3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86881941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "rating_reviews=driver5.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div')\n",
    "rating_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae5e910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Excellent Fabulous Adorable Iphone 11 Value fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I switched to IOS for long term use and for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Perfect iPhone on this budget!! Camera and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5             Terrific   \n",
       "1       5  Best in the market!   \n",
       "2       5       Classy product   \n",
       "3       5    Worth every penny   \n",
       "4       5            Wonderful   \n",
       "..    ...                  ...   \n",
       "95      5            Wonderful   \n",
       "96      5   Highly recommended   \n",
       "97      4            Very Good   \n",
       "98      5            Brilliant   \n",
       "99      5       Classy product   \n",
       "\n",
       "                                          Full Review  \n",
       "0                                      Very very good  \n",
       "1                                         Good Camera  \n",
       "2   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "3   Feeling awesome after getting the delivery of ...  \n",
       "4                              This is amazing at all  \n",
       "..                                                ...  \n",
       "95  Excellent Fabulous Adorable Iphone 11 Value fo...  \n",
       "96  Thanks Flipkart For this amazing deal! I had a...  \n",
       "97  I switched to IOS for long term use and for be...  \n",
       "98  Perfect iPhone on this budget!! Camera and the...  \n",
       "99                 Outstanding performance this phone  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I declare the empty sets where scraped datas are stored. Then I use for loop for extracting datas from next 10 pages.\n",
    "#After this I use find_elements method to scrap rate, review & full review along with relative XPATHS.Lastly I use DataFrame to \n",
    "#make a dataframe based on scraped data.\n",
    "Ratings=[]\n",
    "Review=[]\n",
    "Freview=[]\n",
    "for x in range(10):\n",
    "    #print('scraping page',x+1)\n",
    "    rate=driver5.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for r in rate:\n",
    "        Ratings.append(r.text)\n",
    "    #print('scraping page',x+1)\n",
    "    rev=driver5.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for s in rev:\n",
    "        Review.append(s.text)\n",
    "    #print('scraping page',x+1)    \n",
    "    frev=driver5.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]') \n",
    "    for t in frev:\n",
    "        Freview.append(t.text)\n",
    "    next_button4=driver5.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')[-1]\n",
    "    next_button4.click()\n",
    "    time.sleep(3)\n",
    "#len(Ratings)\n",
    "#len(Review)\n",
    "#len(Freview)\n",
    "df5=pd5.DataFrame({'Rating':Ratings,'Review Summary':Review,'Full Review':Freview})\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42715e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f8dc27f",
   "metadata": {},
   "source": [
    "Q6:Scrape data forfirst 100 sneakers you find whenyou visit: :https://www.flipkart.com/ and search for “sneakers” inthe\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97fb93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd6\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "af2245c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver6=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f3be07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver6.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c5956a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Sneakers\" item as a key value\n",
    "search_product=driver6.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search_product.send_keys('Sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f68ed142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "search_button=driver6.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "46e8ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLYMB</td>\n",
       "      <td>Trending Stylish Casual Outdoor Sneakers Shoes...</td>\n",
       "      <td>₹409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLYMB</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Casual Sneakers Colour Blocked Shoes For Boys ...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Carnival-02 Mens High Top Casual Chunky Sneake...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>kardam&amp;sons luxury fashionable casual sneaker ...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>MADRYN 2.O Sneakers For Men</td>\n",
       "      <td>₹2,763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneaker Casual Shoes For Men | Soft Cushion In...</td>\n",
       "      <td>₹1,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>WINSTON-N Sneakers For Men</td>\n",
       "      <td>₹2,150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RUN SEVEN</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Mens Ultraforce Mid-top Athletic-Inspired Retr...</td>\n",
       "      <td>₹2,713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                                Product Description   Price\n",
       "0          CLYMB  Trending Stylish Casual Outdoor Sneakers Shoes...    ₹409\n",
       "1          CLYMB                                 Sneakers For Women    ₹449\n",
       "2       URBANBOX  Casual Sneakers Colour Blocked Shoes For Boys ...    ₹299\n",
       "3      Deals4you  Carnival-02 Mens High Top Casual Chunky Sneake...    ₹399\n",
       "4   Robbie jones  kardam&sons luxury fashionable casual sneaker ...    ₹449\n",
       "..           ...                                                ...     ...\n",
       "95          PUMA                        MADRYN 2.O Sneakers For Men  ₹2,763\n",
       "96      RED TAPE  Sneaker Casual Shoes For Men | Soft Cushion In...  ₹1,389\n",
       "97          PUMA                         WINSTON-N Sneakers For Men  ₹2,150\n",
       "98     RUN SEVEN                                 Sneakers For Women    ₹999\n",
       "99          PUMA  Mens Ultraforce Mid-top Athletic-Inspired Retr...  ₹2,713\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I declare the empty sets where scraped datas are stored. Then I use for loop for extracting datas from next 3 pages.\n",
    "#After this I use find_elements method to scrap brand,Product description & price along with relative XPATHS.Lastly I use  \n",
    "#DataFrame to make a dataframe based on scraped data.\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "for pages in range(3):\n",
    "    #print('scraping page',pages+1)\n",
    "    b_name=driver6.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for c in b_name:\n",
    "        brand.append(c.text)\n",
    "    #print('scraping page',pages+1)    \n",
    "    b_des1=driver6.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    b_des2=driver6.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    for d in b_des1:\n",
    "        description.append(d.text)\n",
    "    for e in b_des2:\n",
    "        description.append(e.text)\n",
    "    #print('scraping page',pages+1)\n",
    "    b_price=driver6.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for f in b_price:\n",
    "        price.append(f.text)\n",
    "    next_button6=driver6.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')[-1]\n",
    "    next_button6.click()\n",
    "    time.sleep(3)\n",
    "#len(brand)\n",
    "#len(description)\n",
    "#len(price)\n",
    "df6=pd6.DataFrame({'Brand Name':brand[:100],'Product Description':description[:100],'Price':price[:100]})\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60c4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a7ef283",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then\n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0aa100e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd7\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb2fc282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking webdriver is properly working or not\n",
    "driver7=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "503d0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver7.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13f5feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"Laptop\" item as a key value\n",
    "Search_item=driver7.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "Search_item.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a0ac47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "Search_icon=driver7.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "Search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "73b87571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "Cpu_item=driver7.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/div[19]/span')\n",
    "Cpu_item.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b5be1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "Cpu_processor=driver7.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[7]/ul[7]/span/span[13]/li/span/a/span')\n",
    "Cpu_processor.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9c3be611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring empty list, scraping all the titles from that page by using find_elements method along with the relative XPATH.\n",
    "#Then storing all the scraped data to that empty list.\n",
    "title=[]\n",
    "i_title=driver7.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for r in i_title:\n",
    "    title.append(r.text)\n",
    "    \n",
    "#len(title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "007155f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring empty list, scraping all the ratings from that page by using find_elements method along with the relative XPATH.\n",
    "#Then storing all the scraped data to that empty list.\n",
    "ratings=[]\n",
    "i_rating=driver7.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for s in i_rating:\n",
    "    ratings.append(s.text)\n",
    "#len(title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ff152e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring empty list, scraping all the prices from that page by using find_elements method along with the relative XPATH.\n",
    "#Then storing all the scraped data to that empty list.\n",
    "price=[]\n",
    "i_price=driver7.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for t in i_price:\n",
    "    price.append(t.text)\n",
    "#len(price)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fcf2065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Travelmate Business Laptop Intel Core i7-11th ...</td>\n",
       "      <td></td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Modern 14, Intel 12th Gen. i7-1255U, 36CM FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predator Helios Neo 16 Gaming Laptop 13Th Gen ...</td>\n",
       "      <td></td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IdeaPad Slim 3 Intel Core i7 12th Gen 15.6 inc...</td>\n",
       "      <td></td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TUF Gaming F15, 15.6\"(39.62 cms) FHD 144Hz, In...</td>\n",
       "      <td></td>\n",
       "      <td>75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZBook Studio 12th Gen Intel Core i7-12700H 16i...</td>\n",
       "      <td></td>\n",
       "      <td>2,30,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vivobook 15, Intel Core i7-12650H 12th Gen, 15...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Laptop 15s, 12th Gen Intel Core i7-1255U, 15.6...</td>\n",
       "      <td></td>\n",
       "      <td>67,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pavilion 14 11th Gen Intel Core i7 16GB/1TB SS...</td>\n",
       "      <td></td>\n",
       "      <td>84,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Victus Gaming Laptop, 12th Gen Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Travelmate Business Laptop Intel Core i7-11th ...            47,990\n",
       "1  Modern 14, Intel 12th Gen. i7-1255U, 36CM FHD ...            49,990\n",
       "2  Predator Helios Neo 16 Gaming Laptop 13Th Gen ...          1,09,990\n",
       "3  IdeaPad Slim 3 Intel Core i7 12th Gen 15.6 inc...            62,990\n",
       "4  TUF Gaming F15, 15.6\"(39.62 cms) FHD 144Hz, In...            75,990\n",
       "5  ZBook Studio 12th Gen Intel Core i7-12700H 16i...          2,30,060\n",
       "6  Vivobook 15, Intel Core i7-12650H 12th Gen, 15...            59,990\n",
       "7  Laptop 15s, 12th Gen Intel Core i7-1255U, 15.6...            67,490\n",
       "8  Pavilion 14 11th Gen Intel Core i7 16GB/1TB SS...            84,899\n",
       "9  Victus Gaming Laptop, 12th Gen Intel Core i7-1...            82,490"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then a make a DataFrame using that data which are stored inside the empty lists.\n",
    "df7=pd7.DataFrame({'Title':title[0:10],'Ratings':ratings[0:10],'Price':price[0:10]})\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbc466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "192c1eeb",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a386f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd8\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "093717a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is properly working or not.\n",
    "driver8=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "314d03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver8.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "241966ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "top_quotes=driver8.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6e56db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the Quotes & Author names from 10 pages by using find_element and find_elements method \n",
    "#along with the absolute & relative XPATH.Then storing all the scraped data to that empty list.\n",
    "quote=[]\n",
    "author=[]\n",
    "for pagess in range(10):\n",
    "    #print('scraped page',pagess+1)\n",
    "    quot=driver8.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for q in quot:\n",
    "        quote.append(q.text)\n",
    "    auth=driver8.find_elements(By.XPATH,'//div[@class=\"author\"]/a')\n",
    "    for p in auth:\n",
    "        author.append(p.text)\n",
    "    next_page=driver8.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')[-1]\n",
    "    next_page.click()\n",
    "    time.sleep(3)\n",
    "len(quote[:1000])\n",
    "len(author[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7976bd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Inspirational, Life, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Peace, War, Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Life, Strength, Courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Positive, Family, Trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>Inspirational, Life, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                             Type of Quote  \n",
       "0             Inspirational, Life, Success  \n",
       "1                   Peace, War, Government  \n",
       "2                  Life, Strength, Courage  \n",
       "3                  Positive, Family, Trust  \n",
       "4        Inspirational, Life, Motivational  \n",
       "..                                     ...  \n",
       "995      Love, Inspirational, Motivational  \n",
       "996                 Gun, Two, Qualms About  \n",
       "997  Inspirational, Greatness, Best Effort  \n",
       "998                 Spiritual, Truth, Yoga  \n",
       "999   Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the Type of Quotes from 10 pages by using find_element and find_elements method \n",
    "#along with the absolute & relative XPATH.Then storing all the scraped data to that empty list.\n",
    "#Also make a DataFrame by using those datas which are stored inside the empty lists.\n",
    "quoteT=[]\n",
    "for pagesss in range(10):\n",
    "    #print('scraped pages',pagesss+1)\n",
    "    tquote=driver8.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for o in tquote:\n",
    "        quoteT.append(o.text)\n",
    "    next_pages=driver8.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')[-1]\n",
    "    next_pages.click()\n",
    "    time.sleep(3)\n",
    "len(quoteT[:1000])\n",
    "df8=pd8.DataFrame({'Quote':quote[:1000],'Author':author[:1000],'Type of Quote':quoteT[:1000]})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e418c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02175eff",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9699d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd9\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking webdriver is working properly or not\n",
    "driver9=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ba135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver9.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56e5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "gk=driver9.find_element(By.XPATH,'/html/body/div/header/nav/div/div/div[3]/ul/li[3]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ea20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "pm_poster=driver9.find_element(By.XPATH,'/html/body/div[1]/div[8]/section[7]/div[2]/ul/li[3]/figure/a/span/img')\n",
    "pm_poster.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7091a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the PM Names from that table \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "pm_name=[]\n",
    "pmname=driver9.find_elements(By.XPATH,'//td[2][@valign=\"top\"]/div')\n",
    "for u in pmname:\n",
    "    pm_name.append(u.text)\n",
    "len(pm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61c53d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the PM DOB from that table \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "pm_dob=[]\n",
    "pmdob=driver9.find_elements(By.XPATH,'//td[3][@valign=\"top\"]/div')\n",
    "for v in pmdob:\n",
    "    pm_dob.append(v.text)\n",
    "len(pm_dob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72324949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the PM term of office from that table \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "pm_term=[]\n",
    "pmterm=driver9.find_elements(By.XPATH,'//td[4][@valign=\"top\"]')\n",
    "for w in pmterm:\n",
    "    pm_term.append(w.text)\n",
    "len(pm_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f35857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the PM Remarks from that table \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "pm_remark=[]\n",
    "pmremark=driver9.find_elements(By.XPATH,'//td[5][@valign=\"top\"]')\n",
    "for x in pmremark:\n",
    "    pm_remark.append(x.text)\n",
    "len(pm_remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff211318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM Name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Term Of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PM Name           DOB  \\\n",
       "0           Jawahar Lal Nehru   (1889–1964)   \n",
       "1   Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2         Lal Bahadur Shastri   (1904–1966)   \n",
       "3               Indira Gandhi   (1917–1984)   \n",
       "4               Morarji Desai   (1896–1995)   \n",
       "5                Charan Singh   (1902–1987)   \n",
       "6               Indira Gandhi   (1917–1984)   \n",
       "7                Rajiv Gandhi   (1944–1991)   \n",
       "8                 V. P. Singh   (1931–2008)   \n",
       "9             Chandra Shekhar   (1927–2007)   \n",
       "10        P. V. Narasimha Rao   (1921–2004)   \n",
       "11       Atal Bihari Vajpayee  (1924- 2018)   \n",
       "12           H. D. Deve Gowda   (born 1933)   \n",
       "13         Inder Kumar Gujral   (1919–2012)   \n",
       "14       Atal Bihari Vajpayee   (1924-2018)   \n",
       "15             Manmohan Singh   (born 1932)   \n",
       "16              Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term Of Office  \\\n",
       "0   15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1                27 May 1964 to 9 June 1964,\\n13 days   \n",
       "2    9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "3   24 January 1966 to 24 March 1977\\n11 years, 59...   \n",
       "4   24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "5           28 July 1979 to 14 January 1980\\n170 days   \n",
       "6   14 January 1980 to 31 October 1984\\n4 years, 2...   \n",
       "7   31 October 1984 to 2 December 1989\\n5 years, 3...   \n",
       "8       2 December 1989 to 10 November 1990\\n343 days   \n",
       "9          10 November 1990 to 21 June 1991\\n223 days   \n",
       "10     21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "11                16 May 1996 to 1 June 1996\\n16 days   \n",
       "12             1 June 1996 to 21 April 1997\\n324 days   \n",
       "13          21 April 1997 to 19 March 1998 \\n332 days   \n",
       "14    19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "15    22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "16                                 26 May 2014 - 2019   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                First female Prime Minister of India  \n",
       "4   Oldest to become PM (81 years old) and first t...  \n",
       "5             Only PM who did not face the Parliament  \n",
       "6   The first lady who served as PM for the second...  \n",
       "7                Youngest to become PM (40 years old)  \n",
       "8   First PM to step down after a vote of no confi...  \n",
       "9               He belongs to  Samajwadi Janata Party  \n",
       "10                          First PM from South India  \n",
       "11                             PM for shortest tenure  \n",
       "12                          He belongs to  Janata Dal  \n",
       "13                                             ------  \n",
       "14   The first non-congress PM who completed a ful...  \n",
       "15                                      First Sikh PM  \n",
       "16  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also make a DataFrame by using those datas which are stored inside the empty lists.\n",
    "df9=pd9.DataFrame({'PM Name':pm_name,'DOB':pm_dob,'Term Of Office':pm_term,'Remarks':pm_remark})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3d1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bde2a24",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2548f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "import pandas as pd10\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5db1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkng webdriver is working properly or not\n",
    "driver10=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c656dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a website's web-page through the driver\n",
    "driver10.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "678d289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using of find_element method for absolute XPATH, to send \"50 most expensive cars\" item as a key value\n",
    "bar_search=driver10.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "bar_search.send_keys(\"50 most expensive cars\")\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f1068ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "icon_search=driver10.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "icon_search.click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bcf35746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for clicking button I use click() followed by find_element method using absolute XPATH\n",
    "cars_banner=driver10.find_element(By.XPATH,'/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "cars_banner.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e5d7aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the car names from that webpage \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "car_name=[]\n",
    "carNames=driver10.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for f in carNames:\n",
    "    car_name.append(f.text)\n",
    "time.sleep(10)    \n",
    "len(car_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57a51f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring empty list, scraping all the car prices from that webpage \n",
    "#by using find_elements method along with the relative XPATH. Then storing all the scraped data to that empty list.\n",
    "car_price=[]\n",
    "carPrice=driver10.find_elements(By.XPATH,'//div[@class=\"postBody description e-content\"]/p/strong')\n",
    "for g in carPrice:\n",
    "    car_price.append(g.text)\n",
    "time.sleep(10)\n",
    "len(car_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a6b6daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aston Martin Valour</td>\n",
       "      <td>Price: $1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "      <td>Price: $2.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "      <td>Price: $4.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>777 Hypercar</td>\n",
       "      <td>Price: $7.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce La Rose Noire Droptail</td>\n",
       "      <td>Price: $30 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Car Name                        Price\n",
       "0                  Aston Martin Valour          Price: $1.5 Million\n",
       "1                         McLaren Elva          Price: $1.7 Million\n",
       "2                          Czinger 21C          Price: $1.7 Million\n",
       "3                        Ferrari Monza          Price: $1.7 Million\n",
       "4                   Gordon Murray T.33          Price: $1.7 Million\n",
       "5                    Koenigsegg Gemera          Price: $1.7 Million\n",
       "6                          Zenvo TSR-S          Price: $1.7 Million\n",
       "7                   Hennessey Venom F5          Price: $1.8 Million\n",
       "8                      Bentley Bacalar          Price: $1.9 Million\n",
       "9        Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "10              Bentley Mulliner Batur          Price: $2.0 Million\n",
       "11                        Deus Vayanne          Price: $2.0 Million\n",
       "12                         SSC Tuatara          Price: $2.0 Million\n",
       "13                         Lotus Evija          Price: $2.1 Million\n",
       "14                 Aston Martin Vulcan          Price: $2.3 Million\n",
       "15                          Delage D12          Price: $2.3 Million\n",
       "16                 Ferrari Daytona SP3          Price: $2.3 Million\n",
       "17                   McLaren Speedtail          Price: $2.3 Million\n",
       "18                        Rimac Nevera          Price: $2.4 Million\n",
       "19                       Pagani Utopia          Price: $2.5 Million\n",
       "20                Pininfarina Battista          Price: $2.5 Million\n",
       "21                  Gordon Murray T.50          Price: $2.6 Million\n",
       "22                Lamborghini Countach          Price: $2.6 Million\n",
       "23            Mercedes-AMG Project One          Price: $2.7 Million\n",
       "24                        Zenvo Aurora          Price: $2.8 Million\n",
       "25                 Aston Martin Victor          Price: $3.0 Million\n",
       "26         Hennessey Venom F5 Roadster                 $3.0 Million\n",
       "27                    Koenigsegg Jesko          Price: $3.0 Million\n",
       "28               Aston Martin Valkyrie          Price: $3.2 Million\n",
       "29           W Motors Lykan Hypersport          Price: $3.4 Million\n",
       "30                       McLaren Solus                 $3.5 Million\n",
       "31                    Lamborghini Sian          Price: $3.6 million\n",
       "32                    Koenigsegg CC850          Price: $3.7 Million\n",
       "33     Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
       "34                  Lamborghini Veneno          Price: $4.5 Million\n",
       "35                      Bugatti Bolide          Price: $4.7 Million\n",
       "36           Pininfarina B95 Speedster          Price: $4.8 Million\n",
       "37                     Bugatti Mistral          Price: $5.0 Million\n",
       "38                 Pagani Huayra Imola          Price: $5.4 Million\n",
       "39                        Bugatti Divo          Price: $5.8 Million\n",
       "40                 SP Automotive Chaos          Price: $6.4 Million\n",
       "41                    Pagani Codalunga          Price: $7.4 Million\n",
       "42                        777 Hypercar          Price: $7.5 Million\n",
       "43            Mercedes-Maybach Exelero          Price: $8.0 Million\n",
       "44                  Bugatti Centodieci          Price: $9.0 Million\n",
       "45             Bugatti Chiron Profilée         Price: $10.8 Million\n",
       "46                Rolls-Royce Sweptail         Price: $12.8 Million\n",
       "47            Bugatti La Voiture Noire         Price: $13.4 Million\n",
       "48              Rolls-Royce Boat Tail*  Price: $28.0 Million (est.)\n",
       "49  Rolls-Royce La Rose Noire Droptail    Price: $30 Million (est.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also make a DataFrame by using those datas which are stored inside the empty lists.\n",
    "df10=pd10.DataFrame({'Car Name':car_name[:50],'Price':car_price[:50]})\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115d558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
